# Runtime environment
SCBDB_ENV=development

# ─── Database ────────────────────────────────────────────────────────────────
# Application connection string — used by all Rust crates.
DATABASE_URL=postgres://scbdb:changeme@localhost:15432/scbdb

# Docker Compose database settings (configure the PostgreSQL container only;
# NOT read by Rust application code — the application uses DATABASE_URL above).
POSTGRES_DB=scbdb
POSTGRES_PASSWORD=changeme        # REQUIRED — change this in .env
POSTGRES_PORT=15432
POSTGRES_USER=scbdb

# Database pool configuration (all optional — values shown are the defaults)
SCBDB_DB_ACQUIRE_TIMEOUT_SECS=10
SCBDB_DB_MAX_CONNECTIONS=10
SCBDB_DB_MIN_CONNECTIONS=1

# ─── API Security ─────────────────────────────────────────────────────────────
# Comma-separated list of Bearer tokens for all /api/* endpoints.
# Optional in development (auth disabled when empty); REQUIRED in production.
SCBDB_API_KEYS=

# FUTURE: Hashing salt for API key storage (not yet active — see middleware.rs TODO)
# SCBDB_API_KEY_HASH_SALT=

# ─── Server ───────────────────────────────────────────────────────────────────
SCBDB_BIND_ADDR=0.0.0.0:3000

# Logging level when RUST_LOG is not set. Values: trace, debug, info, warn, error
SCBDB_LOG_LEVEL=info

# Optional: RUST_LOG overrides SCBDB_LOG_LEVEL (standard tracing-subscriber env filter).
# Supports per-crate levels, e.g.: RUST_LOG=scbdb_server=debug,scbdb_scraper=warn
# RUST_LOG=

# ─── Config Files ─────────────────────────────────────────────────────────────
SCBDB_BRANDS_PATH=./config/brands.yaml

# ─── External Providers ───────────────────────────────────────────────────────
LEGISCAN_API_KEY=

# ─── LegiScan (optional — value shown is the default) ────────────────────────
# SCBDB_LEGISCAN_REQUEST_TIMEOUT_SECS=30

# ─── Scraper (all optional — values shown are the defaults) ──────────────────
# SCBDB_SCRAPER_REQUEST_TIMEOUT_SECS=30
# SCBDB_SCRAPER_USER_AGENT=scbdb/0.1 (product-intelligence)
# NOTE: parsed but not yet active — concurrency is always 1 in the current implementation.
# Setting this above 1 has no effect until parallel brand collection is implemented.
# SCBDB_SCRAPER_MAX_CONCURRENT_BRANDS=1
# SCBDB_SCRAPER_INTER_REQUEST_DELAY_MS=250
# Maximum retry attempts for transient errors (429 rate limit, 5xx, network failures). Default: 3.
# SCBDB_SCRAPER_MAX_RETRIES=3
# Base delay (seconds) for exponential backoff: delay = base * 2^attempt, floored by Retry-After header. Default: 5.
# SCBDB_SCRAPER_RETRY_BACKOFF_BASE_SECS=5

# ─── Scheduler / Brand Intake Pipeline ───────────────────────────────────────
# Cron schedule for the daily brand intake job. Default: 06:00 UTC daily.
# BRAND_INTAKE_CRON=0 0 6 * * *

# TEI (Text Embeddings Inference) URL for embedding signals during brand intake.
# Used by the server scheduler — distinct from SENTIMENT_TEI_URL below.
# TEI_URL=http://localhost:52000

# YouTube Data API key for YouTube signal collection in the intake pipeline.
# YOUTUBE_API_KEY=

# ─── Sentiment Pipeline ───────────────────────────────────────────────────────
# Required only when running sentiment collection (Phase 4 infrastructure).
# Leave empty to skip sentiment features during core MVP development.

# TEI service URL for embedding generation
SENTIMENT_TEI_URL=http://localhost:52000

# Qdrant vector database URL for storing and retrieving sentiment embeddings
SENTIMENT_QDRANT_URL=http://localhost:53333

# Qdrant collection name for brand sentiment signals
SENTIMENT_QDRANT_COLLECTION=scbdb_sentiment

# Reddit API credentials (if not set, Reddit signal collection is skipped)
REDDIT_CLIENT_ID=
REDDIT_CLIENT_SECRET=
REDDIT_USER_AGENT=scbdb/0.1.0

# Twitter/X sentiment source (optional — omit both to disable)
# Copy values from ~/.config/bird/.env
TWITTER_AUTH_TOKEN=
TWITTER_CT0=

# ─── Brand Newsroom LLM Extraction (optional) ─────────────────────────────────
# Enables LLM-based extraction from brand newsroom pages.
# Requires OPENAI_API_KEY; disabled by default.
OPENAI_API_KEY=
# SENTIMENT_NEWSROOM_LLM_ENABLED=1        # set to 1, true, or yes to enable
# SENTIMENT_NEWSROOM_LLM_MODEL=gpt-4o-mini
